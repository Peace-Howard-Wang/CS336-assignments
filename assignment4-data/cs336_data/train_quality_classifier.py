import re

import requests
from bs4 import BeautifulSoup
from readability import Document


def download_high_quality():
    input_file = "/Users/wanghao/PycharmProjects/CS336/assignment4-data/data/positive_urls.txt"
    output_file = "/Users/wanghao/PycharmProjects/CS336/assignment4-data/data/high_quality.txt"
    success_count = 0

    with open(input_file, "r", encoding="utf-8") as f, \
         open(output_file, "a", encoding="utf-8") as out_f:

        for i, line in enumerate(f, 1):
            url = line.strip()
            try:
                response = requests.get(url, timeout=10)
                if "text/html" not in response.headers.get("Content-Type", ""):
                    print(f"[{i}] Skipped non-HTML content: {url}")
                    continue

                response.encoding = response.apparent_encoding
                if response.status_code == 200:
                    try:
                        doc = Document(response.text)
                        html_content = doc.summary()
                    except Exception as e:
                        print(f"[{i}] readability error: {e} - {url}")
                        continue

                    soup = BeautifulSoup(html_content, "html.parser")
                    text = soup.get_text(separator="\n")
                    text = ''.join(c for c in text if c.isprintable())
                    text = re.sub(r'\n\s*\n', '\n', text).strip()
                    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s.,!?ï¼Œã€‚ï¼ï¼Ÿ]+', '', text)

                    if text:
                        out_f.write(text + "\n<|endoftext|>\n")
                        success_count += 1
                        print(f"[{i}] Downloaded content from {url}")
                    else:
                        print(f"[{i}] No clean text found: {url}")
                else:
                    print(f"[{i}] Failed: Status {response.status_code} - {url}")
            except requests.RequestException as e:
                print(f"[{i}] Error fetching {url}: {e}")

    print(f"Total successful downloads: {success_count}")

import gzip
import random
import re

def download_low_quality():
    input_file = "/Users/wanghao/PycharmProjects/CS336/assignment4-data/data/example.warc.wet.gz"
    output_file = "/Users/wanghao/PycharmProjects/CS336/assignment4-data/data/low_quality.txt"
    sample_size = 1000 # æŠ½å–æ ·æœ¬æ•°é‡
    success_count = 0

    records = []
    current_record = []

    # è¯»å– WET æ–‡ä»¶ï¼ŒæŒ‰æ®µè½åˆ‡åˆ†
    with gzip.open(input_file, "rt", encoding="utf-8", errors="ignore") as f:
        for line in f:
            if line.strip() == "":
                if current_record:
                    records.append("\n".join(current_record).strip())
                    current_record = []
            else:
                current_record.append(line.strip())

    print(f"ğŸ“¦ Loaded {len(records)} records from {input_file}")

    # éšæœºé‡‡æ ·
    sampled = random.sample(records, min(sample_size, len(records)))

    with open(output_file, "a", encoding="utf-8") as out_f:
        for i, text in enumerate(sampled, 1):
            # æ¸…ç†ä¸å¯æ‰“å°å­—ç¬¦
            text = ''.join(c for c in text if c.isprintable())
            text = re.sub(r'\s+', ' ', text).strip()

            if text and len(text.split()) > 5:  # è‡³å°‘å‡ ä¸ªè¯
                out_f.write(text + "\n<|endoftext|>\n")
                success_count += 1
                print(f"[{i}] Saved low-quality sample")
            else:
                print(f"[{i}] Skipped too short/empty")

    print(f"âœ… Total low-quality samples saved: {success_count}")



import fasttext
import os

def train_quality_classifier():
    base_path = "/Users/wanghao/PycharmProjects/CS336/assignment4-data/data"

    high_file = os.path.join(base_path, "high_quality.txt")
    low_file = os.path.join(base_path, "low_quality.txt")
    train_file = os.path.join(base_path, "train_quality.txt")
    model_file = os.path.join(base_path, "quality_classifier.bin")

    # 1. ç”Ÿæˆè®­ç»ƒæ–‡ä»¶ï¼ˆåˆå¹¶ + åŠ æ ‡ç­¾ï¼‰
    with open(train_file, "w", encoding="utf-8") as out_f:
        # é«˜è´¨é‡
        with open(high_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and line != "<|endoftext|>":
                    out_f.write(f"__label__high {line}\n")

        # ä½è´¨é‡
        with open(low_file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and line != "<|endoftext|>":
                    out_f.write(f"__label__low {line}\n")

    print(f"âœ… Training file created: {train_file}")

    # 2. è®­ç»ƒ FastText åˆ†ç±»å™¨
    model = fasttext.train_supervised(
        input=train_file,
        epoch=100,          # è®­ç»ƒè½®æ•°ï¼Œå¯ä»¥è°ƒå¤§
        lr=0.05,            # å­¦ä¹ ç‡
        wordNgrams=2,      # ä½¿ç”¨ bigram
        dim=100,           # å‘é‡ç»´åº¦
        loss="softmax",    # æŸå¤±å‡½æ•°
        verbose=2
    )

    # 3. ä¿å­˜æ¨¡å‹
    model.save_model(model_file)
    print(f"âœ… Model saved to {model_file}")

    return model


def run_classify_quality(text, model):
    """
    ç»™å®šæ–‡æœ¬ï¼Œè¿”å› (label, confidence_score)
    """
    labels, scores = model.predict(text, k=1)
    label = labels[0].replace("__label__", "")
    score = float(scores[0])
    return label, score


if __name__ == "__main__":
    # model = train_quality_classifier()
    model = fasttext.load_model(
        "/Users/wanghao/PycharmProjects/CS336/assignment4-data/data/classifiers/quality_classifier.bin")
    # æµ‹è¯•
    print(run_classify_quality("This article discusses the Malaysian election results", model))
    print(run_classify_quality("hiefdhiewuhfiewhfiweufhwieufewrf34qrq4tE34fewfewf", model))